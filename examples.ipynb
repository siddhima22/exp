{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044e0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 | Loss: 56.9804\n",
      "Epoch  200 | Loss: 6.8641\n",
      "Epoch  400 | Loss: 6.2331\n",
      "Epoch  600 | Loss: 6.1859\n",
      "Epoch  800 | Loss: 6.1785\n",
      "Sales = 0.0182 + (0.0688 * TV) + (0.1822 * Radio)\n",
      "\n",
      "RMSE: 2.485\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"advertising.csv\")\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "features = [\"TV\", \"Radio\"]   \n",
    "target = \"Sales\"\n",
    "\n",
    "X = data[features].values\n",
    "y = data[target].values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "X_b = np.column_stack((np.ones((len(X), 1)), X))\n",
    "\n",
    "theta = np.zeros((X_b.shape[1], 1))\n",
    "lr = 0.00001\n",
    "epochs = 1000\n",
    "m = len(y)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    grad = (2/m) * X_b.T @ (X_b @ theta - y)\n",
    "    theta -= lr * grad\n",
    "    \n",
    "    if epoch % 200 == 0:\n",
    "        loss = np.mean((X_b @ theta - y)**2)\n",
    "        print(f\"Epoch {epoch:4d} | Loss: {loss:.4f}\")\n",
    "\n",
    "y_pred = X_b @ theta\n",
    "rmse = np.sqrt(np.mean((y - y_pred)**2))\n",
    "\n",
    "intercept = theta[0][0]\n",
    "tv_coef = theta[1][0]\n",
    "radio_coef = theta[2][0]\n",
    "\n",
    "print(f\"Sales = {intercept:.4f} + ({tv_coef:.4f} * TV) + ({radio_coef:.4f} * Radio)\")\n",
    "\n",
    "# for i, f in enumerate([\"Intercept\"] + features):\n",
    "#     print(f\"{f}: {theta[i][0]:.4f}\")\n",
    "\n",
    "print(f\"\\nRMSE: {rmse:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# if X.shape[1] == 1:\n",
    "#     plt.figure(figsize=(7,5))\n",
    "#     plt.scatter(X, y, color='blue', label='Actual Data')\n",
    "#     plt.plot(X, y_pred, color='red', label='Regression Line')\n",
    "#     plt.xlabel(features[0])\n",
    "#     plt.ylabel(target)\n",
    "#     plt.title(f'Linear Regression ({features[0]} vs {target})')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True, alpha=0.6)\n",
    "#     plt.show()\n",
    "# else:\n",
    "#     plt.figure(figsize=(6,4))\n",
    "#     plt.scatter(range(len(y)), y, label='Actual', color='blue')\n",
    "#     plt.plot(range(len(y_pred)), y_pred, label='Predicted', color='red', linewidth=2)\n",
    "#     plt.title(\"Actual vs Predicted Sales\")\n",
    "#     plt.xlabel(\"Samples\")\n",
    "#     plt.ylabel(\"Sales\")\n",
    "#     plt.legend()\n",
    "#     plt.grid(alpha=0.4)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "46de2b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name  year  selling_price  km_driven    fuel  \\\n",
      "0             Maruti 800 AC  2007          60000      70000  Petrol   \n",
      "1  Maruti Wagon R LXI Minor  2007         135000      50000  Petrol   \n",
      "2      Hyundai Verna 1.6 SX  2012         600000     100000  Diesel   \n",
      "3    Datsun RediGO T Option  2017         250000      46000  Petrol   \n",
      "4     Honda Amaze VX i-DTEC  2014         450000     141000  Diesel   \n",
      "\n",
      "  seller_type transmission         owner  \n",
      "0  Individual       Manual   First Owner  \n",
      "1  Individual       Manual   First Owner  \n",
      "2  Individual       Manual   First Owner  \n",
      "3  Individual       Manual   First Owner  \n",
      "4  Individual       Manual  Second Owner  \n",
      "Index(['name', 'year', 'selling_price', 'km_driven', 'fuel', 'seller_type',\n",
      "       'transmission', 'owner'],\n",
      "      dtype='object')\n",
      "name             object\n",
      "year              int64\n",
      "selling_price     int64\n",
      "km_driven         int64\n",
      "fuel             object\n",
      "seller_type      object\n",
      "transmission     object\n",
      "owner            object\n",
      "dtype: object\n",
      "                       name  year  selling_price  km_driven    fuel  \\\n",
      "0             Maruti 800 AC  2007          60000      70000  Petrol   \n",
      "1  Maruti Wagon R LXI Minor  2007         135000      50000  Petrol   \n",
      "2      Hyundai Verna 1.6 SX  2012         600000     100000  Diesel   \n",
      "3    Datsun RediGO T Option  2017         250000      46000  Petrol   \n",
      "4     Honda Amaze VX i-DTEC  2014         450000     141000  Diesel   \n",
      "\n",
      "  seller_type transmission         owner  transmission_enc  owner_num  \n",
      "0  Individual       Manual   First Owner                 0          1  \n",
      "1  Individual       Manual   First Owner                 0          1  \n",
      "2  Individual       Manual   First Owner                 0          1  \n",
      "3  Individual       Manual   First Owner                 0          1  \n",
      "4  Individual       Manual  Second Owner                 0          2  \n",
      "Epoch    0 | Loss: 343280373911.6198\n",
      "Epoch  200 | Loss: 334136327006.1069\n",
      "Epoch  400 | Loss: 334135717183.0670\n",
      "Epoch  600 | Loss: 334135107385.6916\n",
      "Epoch  800 | Loss: 334134497613.9799\n",
      "\n",
      "Model: Selling Price = 0.025 + 250.685*Year + -17.279*Owner\n",
      "RMSE: 578043.157\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"CAR DETAILS FROM CAR DEKHO.csv\")\n",
    "print(data.head())\n",
    "print(data.columns)\n",
    "print(data.dtypes)\n",
    "\n",
    "def encode_transmission(x):\n",
    "    if 'Auto' in x: \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "if 'transmission' in data.columns:\n",
    "    data['transmission_enc'] = data['transmission'].apply(encode_transmission)\n",
    "\n",
    "if 'owner' in data.columns:\n",
    "    def encode_owner(x):\n",
    "        if 'First' in x: return 1\n",
    "        elif 'Second' in x: return 2\n",
    "        elif 'Third' in x: return 3\n",
    "        else: return 4\n",
    "    data['owner_num'] = data['owner'].apply(encode_owner)\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "X = data[[\"year\", \"owner_num\"]].values\n",
    "y = data[\"selling_price\"].values.reshape(-1, 1)\n",
    "\n",
    "# Add Bias column\n",
    "X_b = np.column_stack((np.ones((len(X),1)), X))  \n",
    "\n",
    "# Initialize Parameters \n",
    "theta = np.zeros((X_b.shape[1], 1))\n",
    "lr=0.0000001\n",
    "epochs=1000\n",
    "m = len(y)\n",
    "\n",
    "#  Gradient Descent Loop\n",
    "for epoch in range(epochs):\n",
    "    gradients = (2/m) * X_b.T @ (X_b @ theta - y)\n",
    "    theta -= lr * gradients\n",
    "\n",
    "    if epoch % 200 == 0:\n",
    "        loss = np.mean((X_b @ theta - y)**2)\n",
    "        print(f\"Epoch {epoch:4d} | Loss: {loss:.4f}\")\n",
    "\n",
    "\n",
    "intercept = theta[0][0]\n",
    "coef_year = theta[1][0]\n",
    "coef_owner = theta[2][0]\n",
    "\n",
    "print(f\"\\nModel: Selling Price = {intercept:.3f} + {coef_year:.3f}*Year + {coef_owner:.3f}*Owner\")\n",
    "\n",
    "\n",
    "y_pred = X_b @ theta\n",
    "rmse = np.sqrt(np.mean((y - y_pred)**2))\n",
    "print(f\"RMSE: {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399039b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "     User ID  Gender  Age  EstimatedSalary  Purchased\n",
      "0  15624510    Male   19            19000          0\n",
      "1  15810944    Male   35            20000          0\n",
      "2  15668575  Female   26            43000          0\n",
      "3  15603246  Female   27            57000          0\n",
      "4  15804002    Male   19            76000          0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   User ID          400 non-null    int64 \n",
      " 1   Gender           400 non-null    object\n",
      " 2   Age              400 non-null    int64 \n",
      " 3   EstimatedSalary  400 non-null    int64 \n",
      " 4   Purchased        400 non-null    int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 15.8+ KB\n",
      "\n",
      "Info:\n",
      " None\n",
      "\n",
      "Missing values:\n",
      " User ID            0\n",
      "Gender             0\n",
      "Age                0\n",
      "EstimatedSalary    0\n",
      "Purchased          0\n",
      "dtype: int64\n",
      "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
      "0  15624510       1   19            19000          0\n",
      "1  15810944       1   35            20000          0\n",
      "2  15668575       0   26            43000          0\n",
      "3  15603246       0   27            57000          0\n",
      "4  15804002       1   19            76000          0\n",
      "Confusion Matrix:\n",
      " [[50  2]\n",
      " [ 9 19]]\n",
      "Accuracy: 0.8625\n",
      "Precision: 0.9047619047619048\n",
      "Recall: 0.6785714285714286\n",
      "F1 Score: 0.7755102040816326\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "data = pd.read_csv(\"Social_Network_Ads.csv\")\n",
    "\n",
    "print(\"First 5 rows:\\n\", data.head())\n",
    "print(\"\\nInfo:\\n\", data.info())\n",
    "print(\"\\nMissing values:\\n\",data.isnull().sum())\n",
    "data = data.drop_duplicates()\n",
    "data = data.dropna()\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['Gender'] = le.fit_transform(data['Gender'])\n",
    "\n",
    "print(data.head())\n",
    "x=data.drop(\"Purchased\",axis=1)\n",
    "y=data[\"Purchased\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "se=StandardScaler()\n",
    "\n",
    "x_train=se.fit_transform(x_train)\n",
    "x_test=se.transform(x_test)\n",
    "\n",
    "model=SVC(kernel='linear',random_state=42) #kernel=rbf\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "y_pred=model.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision:\",precision_score(y_test,y_pred))\n",
    "print(\"Recall:\",recall_score(y_test,y_pred))\n",
    "print(\"F1 Score:\",f1_score(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a84e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP = np.sum((y_test == 1) & (y_pred == 1))\n",
    "# TN = np.sum((y_test == 0) & (y_pred == 0))\n",
    "# FP = np.sum((y_test == 0) & (y_pred == 1))\n",
    "# FN = np.sum((y_test == 1) & (y_pred == 0))\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(np.array([[TN, FP],[FN, TP]]))\n",
    "\n",
    "# accuracy = (TP + TN) / (TP+TN+FP+FN)\n",
    "# recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "# precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "# f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "# print(\"\\nMetrics (from scratch):\")\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "# print(\"Recall:\", recall)\n",
    "# print(\"Precision:\", precision)\n",
    "# print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dd402b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      " sepal length (cm)    0\n",
      "sepal width (cm)     0\n",
      "petal length (cm)    0\n",
      "petal width (cm)     0\n",
      "species              0\n",
      "dtype: int64\n",
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "Accuracy: 0.9666666666666667\n",
      "Precision: 0.9722222222222222\n",
      "Recall: 0.9629629629629629\n",
      "F1 Score: 0.9658994032395567\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "data=pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "data['species']=iris.target\n",
    "\n",
    "print(\"\\nMissing Values:\\n\", data.isnull().sum())\n",
    "data = data.drop_duplicates()\n",
    "data = data.dropna()\n",
    "\n",
    "x=data.drop(\"species\",axis=1)\n",
    "y=data[\"species\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "se=StandardScaler()\n",
    "x_train=se.fit_transform(x_train)\n",
    "x_test=se.transform(x_test)\n",
    "\n",
    "model=SVC(kernel='linear',random_state=42) #kernel=rbf\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "y_pred=model.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision:\",precision_score(y_test,y_pred,average='macro'))\n",
    "print(\"Recall:\",recall_score(y_test,y_pred,average='macro'))\n",
    "print(\"F1 Score:\",f1_score(y_test,y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "data = data.dropna()\n",
    "\n",
    "x=data.drop(\"target\",axis=1)\n",
    "y=data[\"target\"]\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "model=DecisionTreeClassifier(criterion='gini',max_depth=4,min_samples_split=2,random_state=42) #\"entropy\" or \"log_loss\"\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "y_pred=model.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2b804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.tree import plot_tree\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plot_tree(\n",
    "#     dt,\n",
    "#     filled=True,\n",
    "#     feature_names=iris.feature_names,\n",
    "#     class_names=iris.target_names,\n",
    "#     rounded=True\n",
    "# )\n",
    "# plt.title(f\"Decision Tree using {dt.criterion.upper()} Criterion\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af0f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "data['target'] = iris.target\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "data = data.dropna()\n",
    "\n",
    "x = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model=BaggingClassifier(estimator=DecisionTreeClassifier(),n_estimators=10,random_state=42)\n",
    "# model=RandomForestClassifier(n_estimators=10,random_state=42)\n",
    "# model=GradientBoostingClassifier(n_estimators=10,random_state=42)\n",
    "\n",
    "# model=AdaBoostClassifier(n_estimators=50,learning_rate=0.1,random_state=42)\n",
    "\n",
    "# model=DecisionTreeClassifier(criterion='gini',max_depth=4,min_samples_split=2,random_state=42) #\"entropy\" or \"log_loss\"\n",
    "\n",
    "model.fit(x_train,y_train)  \n",
    "\n",
    "y_pred=model.predict(x_test)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7cafe0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (150, 4)\n",
      "Classes: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Accuracy without PCA: 1.0\n",
      "confusion_matrix [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "Accuracy with PCA: 0.9777777777777777\n",
      "confusion_matrix [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 12]]\n",
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.93      1.00      0.96        13\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "Comparison:\n",
      "Without PCA Accuracy: 1.000\n",
      "With PCA Accuracy:    0.978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#43\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,  classification_report\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Classes:\", iris.target_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "acc_without_pca = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy without PCA:\", acc_without_pca)\n",
    "print(\"confusion_matrix\",confusion_matrix(y_test, y_pred))\n",
    "print(\"classification_report\",classification_report(y_test, y_pred))\n",
    "\n",
    "pca = PCA(n_components=2)  \n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf_pca = RandomForestClassifier(random_state=42)\n",
    "rf_pca.fit(X_train_pca, y_train_pca)\n",
    "y_pred_pca = rf_pca.predict(X_test_pca)\n",
    "\n",
    "acc_with_pca = accuracy_score(y_test_pca, y_pred_pca)\n",
    "print(\"Accuracy with PCA:\", acc_with_pca)\n",
    "print(\"confusion_matrix\",confusion_matrix(y_test_pca, y_pred_pca))\n",
    "print(\"classification_report\",classification_report(y_test_pca, y_pred_pca))\n",
    "\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"Without PCA Accuracy: {acc_without_pca:.3f}\")\n",
    "print(f\"With PCA Accuracy:    {acc_with_pca:.3f}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "083a4f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 | Loss: 13.4290\n",
      "Epoch  200 | Loss: 0.2659\n",
      "Epoch  400 | Loss: 0.1929\n",
      "Epoch  600 | Loss: 0.1596\n",
      "Epoch  800 | Loss: 0.1401\n",
      "\n",
      " Final Accuracy: 98.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# --- Load Data ---\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# --- Add Bias Term ---\n",
    "Xb = np.column_stack((np.ones(len(X)), X))     # Bias column added\n",
    "Yb = np.eye(3)[y]                              # One-hot encoded labels (3 classes)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "theta = np.random.randn(Xb.shape[1], 3)        \n",
    "lr, epochs = 0.1, 1000\n",
    "\n",
    "def softmax(z):\n",
    "    e = np.exp(z - z.max(axis=1, keepdims=True))  \n",
    "    return e / e.sum(axis=1, keepdims=True)\n",
    "\n",
    "def compute_loss(Yb, y_pred):\n",
    "    return -np.mean(np.sum(Yb* np.log(y_pred + 1e-9), axis=1))\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_pred = softmax(Xb @ theta)                # forward pass\n",
    "    loss = compute_loss(Yb, y_pred)             # compute loss\n",
    "    grad = Xb.T @ (y_pred - Yb) / len(Xb)       # gradient\n",
    "    theta -= lr * grad                          # update weights\n",
    "\n",
    "    if i % 200 == 0:\n",
    "        print(f\"Epoch {i:4d} | Loss: {loss:.4f}\")\n",
    "\n",
    "pred = np.argmax(softmax(Xb @ theta), axis=1)\n",
    "acc = np.mean(pred == y)\n",
    "print(f\"\\n Final Accuracy: {acc*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
